import copy
import logging
from typing import Any
from pettingllms.multi_agent_env.base.agent import Agent, AgentData
from pettingllms.multi_agent_env.base.env import Env
from typing import List
from pettingllms.multi_agent_env.math.math_utils import extract_code
from math_verify import parse, verify
from pettingllms.multi_agent_env.math.math_worker import get_code_execution_output
logger = logging.getLogger(__name__)


def truncatefn(s, length=300):
    if isinstance(s, str):
        pass
    else:
        s = str(s)
    if len(s) <= length:
        return s

    return s[: length // 2] + "...(truncated) ..." + s[-length // 2 :]


class ToolAgent(Agent):
    """
    Agent specialized for solving mathematical problems.
    """

    def __init__(self, rollout_idx: int | None = None, **kwargs):
        """
        Initialize the Math Solving Agent's data.
        """
        super().__init__()
        self.rollout_idx = rollout_idx
        # Accept other unrelated keyword arguments for compatibility
        for key, value in (kwargs or {}).items():
            setattr(self, key, value)

    def update_from_env(self, turn_idx: int, env_data: Env):
        # Save environment data
        self.env_data = env_data

        # Support passing either the raw environment (with state) or a wrapped Env
        state = getattr(env_data, "state", None)

        problem = getattr(state, "problem", None)
        code_generated_solution_history = getattr(state, "code_generated_solution_history", None)
        code_extracted_answer_history = getattr(state, "code_extracted_answer_history", None)
        reasoning_generated_solution_history = getattr(state, "reasoning_generated_solution_history", None)
        reasoning_extracted_answer_history = getattr(state, "reasoning_extracted_answer_history", None)
        prompt_for_history="Here is the history of previous reasoning and code solutions generated by LLMs:\n"
        if reasoning_generated_solution_history is not None:
            for i in range(len(reasoning_generated_solution_history)):
                prompt_for_history += f"The turn {i+1} reasoning solution is {reasoning_generated_solution_history[i]}\n"
                prompt_for_history += f"The turn {i+1}th reasoning extracted answer is {reasoning_extracted_answer_history[i]}\n"
        
        if code_generated_solution_history is not None:
            for i in range(len(code_generated_solution_history)):
                prompt_for_history += f"The turn {i+1} code solution is {code_generated_solution_history[i]}\n"
                prompt_for_history += f"The turn {i+1}th code execution result is {code_extracted_answer_history[i]}\n"
        

        if turn_idx == 0:
            formatted_prompt = (
                f"You are a helpful programming assistant that write python code to solve mathematical problems through step-by-step reasoning.\n\n"
                f"Problem:\n{problem}\n\n"
                f"You need to think step by step and provide a complete solution using python code with clear mathematical reasoning.\n"
                f"Please write Python code to solve this problem.\n And you need to print the final answer in the code. Like if the final anwer is the variable x, you need to write ```print(x)```.\n"
                f"Respond in the format:\n\n"
                f"**Code:**\n```python\n# corrected code here\n```\n\n" 
            )
        else:
            formatted_prompt = (
                f"You are a helpful programming assistant that write python code to solve mathematical problems through step-by-step reasoning. \n\n"
                f"Problem:\n{problem}\n\n")
            formatted_prompt += prompt_for_history
            formatted_prompt += (
                f"Please firstly select or refine the best solution from the history of solutions.\n"
                f"The previous solutions are possible to be correct and possible to be all incorrect. If one of the solutions is correct, select it. If all the solutions are incorrect, refine the best solution.\n"
                f"Then solve the problem again. Over all, if the computation is too comlex, the reasoning might be more easier to make mistake. I want you to write the code to solve the problem again.\n")
                
            
            formatted_prompt += (
                f"Respond in the format:\n\n"
                f"**Code:**\n```python\n# corrected code here\n```\n\n" 
            )
        
        self.current_prompt = {"text": formatted_prompt, "image": None}
        
    
    def update_from_model(self, response: str):
        # Parse the response and update agent_data
        self.current_action = extract_code(response)
        return self.current_action

    async def step(self, env_data: Env, env_worker: Any = None):
        """
        Process the generated code solution and evaluate it against the ground truth.
        """
        generated_solution = self.current_action
        env_data.state.code_generated_solution = generated_solution
        ground_truth_answer = env_data.state.ground_truth_answer
        is_correct = False
        code_execution_output = None
        try:
            # execute the code (through ray worker)
            code_execution_output = await get_code_execution_output(
                generated_solution,
                timeout=20.0,
                ray_actor=env_worker,
            )
            env_data.state.code_extracted_answer = parse(code_execution_output)
        except Exception as e:
            code_execution_output = f"error: {e}"
            env_data.state.code_extracted_answer = code_execution_output
        
        # Update history records
        env_data.state.code_generated_solution_history.append(env_data.state.code_generated_solution)
        env_data.state.code_extracted_answer_history.append(env_data.state.code_extracted_answer)
        self.answer_history.append(env_data.state.code_extracted_answer)
        self.action_history.append(self.current_action)
                
        is_correct = verify(parse(code_execution_output), parse(ground_truth_answer))
        if is_correct:
            self.success = True
            self.agent_reward = 1.0
            env_data.state.code_is_correct = True
        else:
            self.success = False
            self.agent_reward = 0.0
            env_data.state.code_is_correct = False
        
        
        
    def calculate_reward(self, env_data: Env):
        self.agent_reward = self.agent_reward
        self.reward_history.append(self.agent_reward)
 
    def reset(self):
        """
        Reset the agent's internal state for a new episode.
        """
        self.current_action = None
        self.current_prompt = None
        self.current_response = None
        self.current_reward = None
        self.current_info = None
        self.current_action = None
        self.current_prompt = None
        self.current_response = None
